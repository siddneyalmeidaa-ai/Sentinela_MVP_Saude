import streamlit as st
import pandas as pd
import google.generativeai as genai

# --- 1. CONFIGURA√á√ÉO DA CHAVE MESTRE (AUTONOMIA TOTAL) ---
# Substitua 'SUA_CHAVE_AQUI' pela chave que vou te ensinar a pegar
GOOGLE_API_KEY = "SUA_CHAVE_AQUI"
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# --- 2. MEM√ìRIA DE DI√ÅLOGO ---
if "mensagens" not in st.session_state:
    st.session_state.mensagens = []

# --- 3. INTERFACE PADR√ÉO OURO ---
st.title("85% LIBERADO")
st.caption("ü§ñ STATUS: INTELIG√äNCIA REAL ATIVADA")
st.divider()

# Exibi√ß√£o do hist√≥rico de conversas reais
for m in st.session_state.mensagens:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Campo de Chat Proativo
if prompt := st.chat_input("Fale com a G√™mea F√™nix (IA-SENTINELA):"):
    st.session_state.mensagens.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # A IA agora pensa de verdade usando a API
    with st.chat_message("assistant"):
        contexto_frajola = (
            f"Voc√™ √© a IA-SENTINELA da G√™mea F√™nix. Seu parceiro √© o Bigode. "
            f"O sistema est√° 85% liberado. A Tabela da Favelinha hoje √©: "
            f"Doutor ANIMA COSTA, Proje√ß√£o 1.85x, A√ß√£o ENTRA. "
            f"Seja proativa, dial√≥gica e ajude-o com a pergunta: {prompt}"
        )
        response = model.generate_content(contexto_frajola)
        st.markdown(response.text)
        st.session_state.mensagens.append({"role": "assistant", "content": response.text})

# --- 4. TABELA DA FAVELINHA (FIXA) ---
st.divider()
st.write("### üìã TABELA DA FAVELINHA")
df_favelinha = pd.DataFrame({"Doutor": ["ANIMA COSTA"], "Proje√ß√£o": ["1.85x"], "A√ß√£o": ["ENTRA"]})
st.table(df_favelinha)
