import streamlit as st
import pandas as pd
import urllib.parse

# --- 1. MOTOR DE DI√ÅLOGO PROATIVO (C√âREBRO COM AUTONOMIA) ---
def motor_fenix_proativo(mensagem):
    msg = mensagem.lower()
    
    # RESPOSTA DIN√ÇMICA (IA toma iniciativa)
    if any(x in msg for x in ["pend√™ncia", "ajuda", "fazer", "pr√≥ximo"]):
        return ("Bigode, identifiquei que ainda temos 15% pendentes. Proativamente, "
                "sugiro focar no Doutor ANIMA COSTA. A proje√ß√£o de 1.85x √© o sinal "
                "ideal. Quer que eu audite a pr√≥xima rodada agora?")
    
    # RESPOSTA DE DI√ÅLOGO (Para perguntas gerais como 'Previs√£o do tempo')
    return (f"Entendi sua d√∫vida sobre '{mensagem}'. Como sua IA-SENTINELA, "
            "estou processando isso na Vis√£o Global para garantir que n√£o afete "
            "nossa opera√ß√£o. O que mais voc√™ deseja que eu analise hoje?")

# --- 2. INTERFACE DE CHAT (ESTILO DI√ÅLOGO REAL) ---
st.title("85% LIBERADO")
st.caption("ü§ñ STATUS: AUTONOMIA E DI√ÅLOGO ATIVOS")
st.divider()

if "mensagens" not in st.session_state:
    st.session_state.mensagens = [{"role": "assistant", "content": "Ol√° Bigode! Sou sua IA-SENTINELA. Como vamos acelerar hoje?"}]

# Exibi√ß√£o do Chat
for m in st.session_state.mensagens:
    with st.chat_message(m["role"]):
        st.write(m["content"])

# Entrada de Di√°logo
if prompt := st.chat_input("Fale com a G√™mea F√™nix..."):
    st.session_state.mensagens.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    resposta = motor_fenix_proativo(prompt)
    
    st.session_state.mensagens.append({"role": "assistant", "content": resposta})
    with st.chat_message("assistant"):
        st.write(resposta)

# --- 3. TABELA DA FAVELINHA (FIXA) ---
st.divider()
st.write("### üìã TABELA DA FAVELINHA")
df_favelinha = pd.DataFrame({"Doutor": ["ANIMA COSTA"], "Proje√ß√£o": ["1.85x"], "A√ß√£o": ["ENTRA"]})
st.table(df_favelinha)
